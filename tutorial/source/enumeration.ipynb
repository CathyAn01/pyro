{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with discrete latent variables\n",
    "\n",
    "This tutorial describes Pyro's enumeration strategy for discrete latent variable models.\n",
    "First read the [Tensor Shapes Tutorial](http://pyro.ai/examples/tensor_shapes.html) and the [Gaussian Mixture Model Tutorial](http://pyro.ai/examples/gmm.html).\n",
    "\n",
    "#### Summary \n",
    "\n",
    "- Pyro implements automatic enumeration over discrete latent variables.\n",
    "- This strategy can be used alone or inside SVI (via [TraceEnum_ELBO](http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.traceenum_elbo.TraceEnum_ELBO)), HMC, or NUTS.\n",
    "- Annotate a sample site `infer={\"enumerate\": \"parallel\"}` to trigger enumeration.\n",
    "- If a sample site determines downstream structure, instead use `{\"enumerate\": \"sequential\"}`.\n",
    "- Write your models to allow arbitrarily deep batching on the left, e.g. use broadcasting.\n",
    "- Inference cost is exponential in treewidth, so try to write models with narrow treewidth.\n",
    "- If you have trouble, let us know on [forum.pyro.ai](https://forum.pyro.ai)!\n",
    "\n",
    "#### Table of contents\n",
    "\n",
    "- [Overview](#Overview)\n",
    "- [Mechanics of enumeration](#Mechanics-of-enumeration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
    "\n",
    "pyro.enable_validation()\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview <a class=\"anchor\" id=\"Overview\"></a>\n",
    "\n",
    "Pyro's enumeration strategy encompasses popular algorithms including variable elimination, exact message passing, forward-filter-backward-sample, inside-out, Baum-Welch, and many other special-case algorithms. Aside from enumeration, Pyro implements a number of inference strategies including variational inference ([SVI](http://docs.pyro.ai/en/dev/inference_algos.html)) and monte carlo ([HMC](http://docs.pyro.ai/en/dev/mcmc.html#pyro.infer.mcmc.HMC) and [NUTS](http://docs.pyro.ai/en/dev/mcmc.html#pyro.infer.mcmc.NUTS)). Enumeration can be used either as a stand-alone strategy, or as a component of other strategies. Thus enumeration allows Pyro do marginalize out discrete latent variables in HMC and SVI models, and to use variational enumeration of discrete variables in SVI guides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mechanics of enumeration  <a class=\"anchor\" id=\"Mechanics-of-enumeration\"></a>\n",
    "\n",
    "The core idea of enumeration is to interpret discrete [pyro.sample](http://docs.pyro.ai/en/dev/primitives.html#pyro.sample) statements as full enumeration rather than random sampling. Other inference algorithms can then sum out the enumerated values. For example a sample statement might return scalar shape under the standard \"sample\" interpretation (we'll illustrate with trivial model and guide):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guide z = 4\n",
      "model z = 4\n"
     ]
    }
   ],
   "source": [
    "def model():\n",
    "    z = pyro.sample(\"z\", dist.Categorical(torch.ones(5)))\n",
    "    print('model z = {}'.format(z))\n",
    "\n",
    "def guide():\n",
    "    z = pyro.sample(\"z\", dist.Categorical(torch.ones(5)))\n",
    "    print('guide z = {}'.format(z))\n",
    "\n",
    "elbo = Trace_ELBO()\n",
    "elbo.loss(model, guide);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However under the enumeration interpretation, the same sample site will return a fully enumerated set of values, based on its distribution's [.enumerate_support()](https://pytorch.org/docs/stable/distributions.html#torch.distributions.distribution.Distribution.enumerate_support) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guide z = tensor([ 0,  1,  2,  3,  4])\n",
      "model z = tensor([ 0,  1,  2,  3,  4])\n"
     ]
    }
   ],
   "source": [
    "elbo = TraceEnum_ELBO(max_plate_nesting=0)\n",
    "elbo.loss(model, config_enumerate(guide, \"parallel\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we've used \"parallel\" enumeration to enumerate along a new tensor dimension. This is cheap and allows Pyro to parallelize computation, but requires downstream program structure to avoid branching on the value of `z`. To support dynamic program structure, you can instead use \"sequential\" enumeration, which runs the entire model,guide pair once per sample value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guide z = 4\n",
      "model z = 4\n",
      "guide z = 3\n",
      "model z = 3\n",
      "guide z = 2\n",
      "model z = 2\n",
      "guide z = 1\n",
      "model z = 1\n",
      "guide z = 0\n",
      "model z = 0\n"
     ]
    }
   ],
   "source": [
    "elbo = TraceEnum_ELBO(max_plate_nesting=0)\n",
    "elbo.loss(model, config_enumerate(guide, \"sequential\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel enumeration is cheaper but more complex than sequential enumeration, so we'll focus the rest of this tutorial on the parallel variant. Note that both forms can be interleaved.\n",
    "\n",
    "### Multiple latent variables\n",
    "\n",
    "We just saw that a single discrete sample site can be enumerated via nonstandard interpretation. A model with a single discrete latent variable is a mixture model. Models with multiple discrete latent variables can be more complex, including HMMs, CRFs, DBNs, and other structured models. In models with multiple discrete latent variables, Pyro enumerates each in a different tensor dimension (counting from the right; see [Tensor Shapes Tutorial](http://pyro.ai/examples/tensor_shapes.html)). This allows Pyro to determine the dependency graph among varaibles and then perform cheap exact inference using variable elimination algorithms.\n",
    "\n",
    "To understand enumeration dimension allocation, consider the following model, where here we collapse variables out of the model, rather than enumerate them in the guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model x.shape = torch.Size([3])\n",
      "model y.shape = torch.Size([3, 1])\n",
      "model z.shape = torch.Size([3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "@config_enumerate(default=\"parallel\")\n",
    "def model():\n",
    "    p = pyro.param(\"p\", torch.randn(3, 3).exp())\n",
    "    x = pyro.sample(\"x\", dist.Categorical(p[0]))\n",
    "    y = pyro.sample(\"y\", dist.Categorical(p[x]))\n",
    "    z = pyro.sample(\"z\", dist.Categorical(p[y]))\n",
    "    print('model x.shape = {}'.format(x.shape))\n",
    "    print('model y.shape = {}'.format(y.shape))\n",
    "    print('model z.shape = {}'.format(z.shape))\n",
    "    \n",
    "def guide():\n",
    "    pass\n",
    "\n",
    "pyro.clear_param_store()\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=0)\n",
    "elbo.loss(model, guide);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plates and enumeration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to write a tractable model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whether to enumerate in the guide or model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
